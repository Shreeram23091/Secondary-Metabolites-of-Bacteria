{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qzWPDRV9cQy",
        "outputId": "0bc11b86-c922-4af7-b2ac-9b9b26a8cb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import ast\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "df = pd.read_csv(\"/content/Task2_pubmed_secondary_metabolites_Bacteria.csv\", encoding=\"latin-1\")\n",
        "df['ABSTRACT'] = df['ABSTRACT'].astype(str)\n",
        "with open('/content/pathway_names.txt', 'r') as file:\n",
        "    words_to_search = [word.strip().lower() for word in file.readlines()]\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_fulltext(pmcid):\n",
        "    url = f\"https://www.ncbi.nlm.nih.gov/pmc/articles/{pmcid}/\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    fulltext = soup.find(\"div\", {\"class\": \"fullText\"})\n",
        "    if fulltext:\n",
        "        return fulltext.get_text()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "matches = {}\n",
        "for index, row in df.iterrows():\n",
        "    pmid = row[\"PMID\"]\n",
        "    pmcid = row['PMCID']\n",
        "    if pd.notnull(pmcid):\n",
        "        fulltext = fetch_fulltext(pmcid)\n",
        "        if fulltext:\n",
        "            paragraph = fulltext.lower()\n",
        "            matches[pmid] = []\n",
        "            for word in words_to_search:\n",
        "                if word in paragraph:\n",
        "                    matches[pmid].append(word)\n",
        "        else:\n",
        "            paragraph = row['ABSTRACT'].lower()\n",
        "            matches[pmid] = []\n",
        "            for word in words_to_search:\n",
        "                if word in paragraph:\n",
        "                    matches[pmid].append(word)\n",
        "    else:\n",
        "        paragraph = row['ABSTRACT'].lower()\n",
        "        matches[pmid] = []\n",
        "        for word in words_to_search:\n",
        "            if word in paragraph:\n",
        "                matches[pmid].append(word)\n",
        "\n",
        "matches_df = pd.DataFrame({'pmid': list(matches.keys()), 'pathways': list(matches.values())})\n",
        "matches_df.to_csv(\"virus_Pathways_20.csv\", index=False)\n",
        "pathways_df = pd.read_csv(\"/content/virus_Pathways_20.csv\")\n",
        "for index, row in pathways_df.iterrows():\n",
        "    pathways_df['pathways'][index] = ast.literal_eval(pathways_df['pathways'][index])\n",
        "\n",
        "empty_list_count = pathways_df['pathways'].apply(lambda x: len(x) == 2).sum()\n",
        "print(\"Number of rows with empty lists:\", empty_list_count)\n",
        "\n",
        "df_exploded = pathways_df['pathways'].explode()\n",
        "unique_pathways = df_exploded.unique()\n",
        "print(unique_pathways)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming unique_pathways is a numpy array\n",
        "unique_pathways_list = unique_pathways.astype(str)\n",
        "\n",
        "# Replace nan values with empty strings\n",
        "unique_pathways_list[unique_pathways_list == 'nan'] = ''\n",
        "\n",
        "# Convert to a list and remove duplicates\n",
        "unique_pathways_list = list(set(unique_pathways_list))\n",
        "\n",
        "# Remove empty string from the list if needed\n",
        "unique_pathways_list = [pathway for pathway in unique_pathways_list if pathway]\n",
        "\n",
        "unique_count = len(set(unique_pathways_list))\n",
        "set_of_pathways = set(unique_pathways_list)\n",
        "pathways_df = pd.read_csv(\"/content/virus_Pathways_20.csv\")\n",
        "\n",
        "pmid_series = []\n",
        "pathways_series = []\n",
        "length_series = []\n",
        "\n",
        "for pathway in set_of_pathways:\n",
        "    filter_df = pathways_df[pathways_df['pathways'].str.contains(pathway)]\n",
        "    pmids = filter_df['pmid'].tolist()\n",
        "    pmidlst = \"\"\n",
        "    for p in pmids:\n",
        "        pmidlst = pmidlst + str(p) + \",\"\n",
        "    pmidlst = pmidlst[:-1]\n",
        "    pathways_series.append(pathway)\n",
        "    pmid_series.append(pmidlst)\n",
        "    length_series.append(len(pmids))\n",
        "\n",
        "consensus_pathways_df = pd.DataFrame({'pathways': pathways_series, 'PMID': pmid_series, 'length': length_series})\n",
        "consensus_pathways_df.to_csv(\"virus_Pathways_20_final.csv\", index=False)"
      ],
      "metadata": {
        "id": "NQD0Qisa9ibb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4259030f-2bca-4ce8-b1fb-4590df2caf06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with empty lists: 87\n",
            "[nan 'pathways' 'metabolic pathways' 'two-component system'\n",
            " 'breast cancer' 'apoptosis' 'cell cycle' 'melanoma' 'carbon metabolism'\n",
            " 'sulfur metabolism' 'plant-pathogen interaction' 'proteasome'\n",
            " 'parkinson disease' 'nitrogen metabolism' 'prodigiosin biosynthesis'\n",
            " 'streptomycin biosynthesis' 'prostate cancer' 'toxoplasmosis'\n",
            " 'hepatocellular carcinoma' 'rna degradation'\n",
            " 'biosynthesis of amino acids'\n",
            " 'microbial metabolism in diverse environments' 'legionellosis'\n",
            " 'pancreatic cancer' 'pertussis' 'osteoclast differentiation'\n",
            " 'tight junction' 'anthocyanin biosynthesis' 'nucleotide excision repair'\n",
            " 'glioma' 'base excision repair' 'ampk signaling pathway'\n",
            " 'bacterial secretion system' 'methane metabolism'\n",
            " 'cysteine and methionine metabolism' 'biotin metabolism'\n",
            " 'terpenoid backbone biosynthesis' 'steroid hormone biosynthesis'\n",
            " 'pathways in cancer' 'proteoglycans in cancer' 'zeatin biosynthesis'\n",
            " 'bladder cancer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aUGNqqIn-JSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}